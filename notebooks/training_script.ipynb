{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a4c534-b37c-4a35-9cf7-e2b0110e7bf3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install torch torchvision torchaudio accelerate transformers\n",
    "!pip install transformers accelerate datasets -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb0edae-151c-41e2-b46a-392e6c1a3010",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, Trainer, TrainingArguments, DataCollatorForLanguageModeling, pipeline\n",
    "from datasets import load_dataset\n",
    "from huggingface_hub import login\n",
    "from huggingface_hub import Repository\n",
    "import torch\n",
    "\n",
    "token = \"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\"\n",
    "login(token = token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4208d967-d0c8-4486-b50c-0d06709e61ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data_files = {\"train\": \"1337_school_training.csv\", \"validation\": \"1337_school_validation.csv\"}\n",
    "dataset = load_dataset('csv', data_files=data_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439c5fe8-abff-4599-83c7-1073f6af3976",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the tokenizer and model\n",
    "model_name = 'meta-llama/Meta-Llama-3-8B-Instruct'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0159f3c0-b328-4944-b72f-401efc0ebdfb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tokenize the dataset\n",
    "def tokenize_function(examples):\n",
    "    inputs = tokenizer(examples[\"input\"], padding=\"max_length\", truncation=True, max_length=3000)\n",
    "    outputs = tokenizer(examples[\"output\"], padding=\"max_length\", truncation=True, max_length=3000)\n",
    "    inputs[\"labels\"] = outputs[\"input_ids\"]\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6ad7285-2fca-4237-baf0-acf74b035a0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.resize_token_embeddings(len(tokenizer))\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f24617-168d-4997-bdb1-ff93b7b43526",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check CUDA availability\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e7c2c6-03f4-483e-bcac-909344d4a3d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    save_total_limit=2,\n",
    "    no_cuda=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98ed3024-4394-4a30-bbae-1a55ecd2c3d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374ada8a-c5f4-45ef-b620-43b8046c84c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fine-tuning\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8079d677-f73d-42fb-98de-6639f3804249",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the fine-tuned model\n",
    "trainer.save_model(\"./results/fine-tuned-model\")\n",
    "\n",
    "# repo = Repository(local_dir=\"fine-tuned-model-dir\", token=token)\n",
    "# repo.create_repo(name=\"1337bot\", exist_ok=True)\n",
    "# repo.push_to_hub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d94b01c-d0d5-43e2-b6db-a7bf78cc816d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
